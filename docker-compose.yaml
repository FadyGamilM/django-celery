version: '3.8'
services:
  redis:
    image: redis:latest
    container_name: redis
    ports:
      - "6379:6379" # browser:container

  django:
    image: django-celery
    container_name: django_app
    build:
      context: .
      dockerfile: Dockerfile
    command: python manage.py runserver 0.0.0.0:8000
    volumes:
      - .:/usr/src/app/ # ensure  the WORKDIR in Dockerfile is /usr/src/app
    ports:
      - "8000:8000" # browser:container
    environment:
      - DEBUG=True
      - SECRET_KEY=8940129401294gasgas85212dsa
      - ALLOWED_HOSTS=localhost, 127.0.0.1
    depends_on:
      - redis

  # celery:
  #   image: django-celery
  #   container_name: celery_app
  #   build:
  #     context: . # local codebase will be used for both celery app and django server app 
  #   command: celery --app=djangocelery worker -l INFO
  #   volumes:
  #     - .:/usr/src/app/ # ensure  the WORKDIR in Dockerfile is /usr/src/app
  #   depends_on:
  #     - redis
  #     - django
  #   environment:
  #     - DEBUG=True
  #     - SECRET_KEY=8940129401294gasgas85212dsa
  #     - ALLOWED_HOSTS=localhost, 127.0.0.1

  standalone_celery:
    image: celery-standalone # if you want to run a standalone celery worker and not reuse the codebase and the dockerfile of the other svcs, use a unique image name isntead of the image that is used for the django and celery services
    container_name: celery_standalone_app
    build:
      context: ./celery-worker-svc # local codebase will be used for both celery app and django server app 
      dockerfile: ./Dockerfile
    command: celery --app=celery worker -l INFO # --app=celery is the name of the celery file app (celery.py)
    volumes:
      - ./celery-worker-svc:/usr/src/app/ # ensure  the WORKDIR in Dockerfile is /usr/src/app
    depends_on:
      - redis
      - django
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0